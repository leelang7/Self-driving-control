import rclpy
from rclpy.node import Node
from sensor_msgs.msg import LaserScan, Imu
import cv2
import numpy as np
import math
import asyncio
import websockets
import threading

# [ì¤‘ìš”] ë¡œë´‡ ì œì–´ ëª¨ë“ˆ
try:
    from robot_control import RobotController
    HAS_ROBOT_CONTROL = True
except ImportError:
    print("âš ï¸ ê²½ê³ : 'robot_control.py'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    HAS_ROBOT_CONTROL = False

ROBOT_ID = "robot1" 
SERVER_URI = f"wss://hsdstnapptmqhcmc.tunnel.elice.io/ws/robot/{ROBOT_ID}"

class IntegratedFleetNode(Node):
    def __init__(self):
        super().__init__('integrated_fleet_node')
        
        # 1. ë¡œë´‡ ì œì–´
        self.robot = None
        if HAS_ROBOT_CONTROL:
            try:
                self.robot = RobotController()
                self.get_logger().info("âœ… RobotController ì—°ê²° ì„±ê³µ")
            except Exception as e:
                self.get_logger().error(f"âŒ RobotController ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        # 2. ì¹´ë©”ë¼
        self.cap = cv2.VideoCapture(0)
        if self.cap.isOpened():
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)
            self.get_logger().info(f"ðŸŽ¥ ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ (ID: {ROBOT_ID})")
        else:
            self.get_logger().error("âš ï¸ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

        # 3. ROS êµ¬ë…
        self.create_subscription(LaserScan, '/scan_raw', self.lidar_callback, 10)
        self.create_subscription(Imu, '/imu', self.imu_callback, 10)
        
        self.latest_scan = None
        
        # ==========================================
        # â˜… [ì§€ë„ ê³ ì • ëª¨ë“œ ì„¤ì •]
        # ==========================================
        self.display_yaw = 0.0       
        self.last_raw_yaw = None     
        
        # ë°©í–¥ ì„¤ì • (ì™¼ìª½ ëŒ ë•Œ í™”ì‚´í‘œë„ ì™¼ìª½ ê°€ë„ë¡ 1 ì„¤ì •)
        self.YAW_DIRECTION = 1       
        
        # ë–¨ë¦¼ ë°©ì§€ (ë„ˆë¬´ ë¯¼ê°í•˜ë©´ 0.01ë¡œ ì˜¬ë¦¬ì„¸ìš”)
        self.DRIFT_THRESHOLD = 0.005

        # ë§µ ì„¤ì •
        self.MAP_SIZE = 400
        self.MAX_DIST = 4.0
        self.SCALE = (self.MAP_SIZE / 2) / self.MAX_DIST
        self.CENTER = int(self.MAP_SIZE / 2)

        self.get_logger().info(f"ðŸš€ [Fleet Client] ë¡œë´‡ ID: {ROBOT_ID} ì‹œìž‘")

    def lidar_callback(self, msg):
        self.latest_scan = msg

    def imu_callback(self, msg):
        q = msg.orientation
        
        # 1. í˜„ìž¬ ì„¼ì„œê°’(Raw)
        current_raw = math.atan2(2*(q.w*q.z + q.x*q.y), 1 - 2*(q.y*q.y + q.z*q.z))
        current_raw *= self.YAW_DIRECTION

        if self.last_raw_yaw is None:
            self.last_raw_yaw = current_raw
            return

        # 2. ë³€í™”ëŸ‰ ê³„ì‚°
        delta = current_raw - self.last_raw_yaw

        # ê°ë„ ëŠê¹€ ë°©ì§€
        if delta > math.pi: delta -= 2 * math.pi
        elif delta < -math.pi: delta += 2 * math.pi

        # 3. ë–¨ë¦¼ ë°©ì§€
        if abs(delta) < self.DRIFT_THRESHOLD:
            delta = 0.0

        # 4. ê°ë„ ëˆ„ì  (ì—¬ê¸°ê°€ ë¡œë´‡ì˜ ì ˆëŒ€ ë°©í–¥)
        self.display_yaw += delta
        self.last_raw_yaw = current_raw

    def reset_gyro(self):
        self.display_yaw = 0.0
        self.last_raw_yaw = None
        self.get_logger().info("ðŸ”„ ë¦¬ì…‹ë¨")

    def get_camera_frame(self):
        if self.cap.isOpened():
            ret, frame = self.cap.read()
            if ret: return frame
        return None

    def draw_premium_radar(self):
        img = np.full((self.MAP_SIZE, self.MAP_SIZE, 3), 20, dtype=np.uint8)
        
        COLOR_GRID = (60, 60, 60)       
        COLOR_TEXT = (150, 150, 150)    
        COLOR_LIDAR = (0, 255, 200)     
        COLOR_ROBOT = (0, 100, 255)     
        COLOR_HEADING = (0, 0, 255)     

        # ê·¸ë¦¬ë“œ
        for r in range(1, int(self.MAX_DIST) + 1):
            radius = int(r * self.SCALE)
            cv2.circle(img, (self.CENTER, self.CENTER), radius, COLOR_GRID, 1, cv2.LINE_AA)
            cv2.putText(img, f"{r}m", (self.CENTER + 5, self.CENTER - radius + 12), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, COLOR_TEXT, 1, cv2.LINE_AA)

        # ê°ë„ì„  (ë°°ê²½ì´ë¯€ë¡œ ê³ ì •)
        max_r_pixel = int(self.MAX_DIST * self.SCALE)
        for angle in range(0, 360, 45):
            rad = math.radians(angle)
            x_end = self.CENTER - int(max_r_pixel * math.sin(rad))
            y_end = self.CENTER - int(max_r_pixel * math.cos(rad))
            cv2.line(img, (self.CENTER, self.CENTER), (x_end, y_end), COLOR_GRID, 1, cv2.LINE_AA)
            
            disp_angle = angle if angle <= 180 else angle - 360
            text_x = self.CENTER - int((max_r_pixel + 20) * math.sin(rad)) - 15
            text_y = self.CENTER - int((max_r_pixel + 20) * math.cos(rad)) + 5
            cv2.putText(img, f"{disp_angle}", (text_x, text_y), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, COLOR_TEXT, 1, cv2.LINE_AA)

        cv2.line(img, (self.CENTER, 0), (self.CENTER, self.MAP_SIZE), COLOR_GRID, 1)
        cv2.line(img, (0, self.CENTER), (self.MAP_SIZE, self.CENTER), COLOR_GRID, 1)

        # â˜… [í•µì‹¬ ìˆ˜ì •] ë¼ì´ë‹¤ ê·¸ë¦¬ê¸°
        if self.latest_scan:
            ranges = np.array(self.latest_scan.ranges)
            angle_min = self.latest_scan.angle_min
            angle_inc = self.latest_scan.angle_increment
            
            # ë¡œë´‡ì˜ í˜„ìž¬ íšŒì „ê° (ì´ê±¸ ë”í•´ì¤˜ì•¼ ë²½ì´ ê³ ì •ë¨)
            robot_yaw = self.display_yaw

            for i, r in enumerate(ranges):
                if 0.1 < r < self.MAX_DIST:
                    # ê¸°ì¡´: theta = angle_min + i * angle_inc (ë¡œë´‡ ê¸°ì¤€)
                    # ìˆ˜ì •: ë¡œë´‡ íšŒì „ê°(robot_yaw)ì„ ë”í•´ì„œ 'ì ˆëŒ€ ì¢Œí‘œ'ë¡œ ë³€í™˜
                    theta = angle_min + i * angle_inc + robot_yaw
                    
                    x = self.CENTER - int(r * self.SCALE * math.sin(theta)) 
                    y = self.CENTER - int(r * self.SCALE * math.cos(theta))
                    
                    if 0 <= x < self.MAP_SIZE and 0 <= y < self.MAP_SIZE:
                        cv2.circle(img, (x, y), 1, COLOR_LIDAR, -1, cv2.LINE_AA)

            # â˜… [í•µì‹¬ ìˆ˜ì •] í™”ì‚´í‘œ ê·¸ë¦¬ê¸°
            # í™”ì‚´í‘œëŠ” ë¡œë´‡ì˜ ë°©í–¥ì´ë¯€ë¡œ robot_yaw ë°©í–¥ìœ¼ë¡œ íšŒì „í•´ì•¼ í•¨
            heading_deg = math.degrees(robot_yaw)
            heading_deg = (heading_deg + 180) % 360 - 180
            
            cv2.putText(img, f"ID: {ROBOT_ID} | YAW: {heading_deg:.1f}", (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)
            
            imu_len = self.MAP_SIZE // 3
            # í™”ì‚´í‘œ ëì  ê³„ì‚° (ë¡œë´‡ ê°ë„ ë°˜ì˜)
            imu_x = self.CENTER - int(imu_len * math.sin(robot_yaw))
            imu_y = self.CENTER - int(imu_len * math.cos(robot_yaw))
            
            # í™”ì‚´í‘œ ê·¸ë¦¬ê¸° (ì´ì œ í™”ì‚´í‘œê°€ ëŒì•„ê°‘ë‹ˆë‹¤!)
            cv2.arrowedLine(img, (self.CENTER, self.CENTER), (imu_x, imu_y), 
                            COLOR_HEADING, 3, cv2.LINE_AA, tipLength=0.2)
        else:
            cv2.putText(img, f"ID: {ROBOT_ID} | SCANNING...", (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1)

        # ë¡œë´‡ ë³¸ì²´ ë§ˆì»¤ (ì–˜ëŠ” í•­ìƒ ê°€ìš´ë° ê³ ì •)
        pt1 = (self.CENTER, self.CENTER - 8)
        pt2 = (self.CENTER - 6, self.CENTER + 6)
        pt3 = (self.CENTER + 6, self.CENTER + 6)
        cv2.drawContours(img, [np.array([pt1, pt2, pt3])], 0, COLOR_ROBOT, -1)

        return img

    def get_fused_image(self):
        frame = self.get_camera_frame()
        if frame is None:
            cam_img = np.zeros((300, 400, 3), np.uint8)
            cv2.putText(cam_img, "NO CAMERA", (120, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)
        else:
            cam_img = cv2.resize(frame, (400, 300))
        lidar_img = self.draw_premium_radar()
        if cam_img.shape[1] != lidar_img.shape[1]:
            lidar_img = cv2.resize(lidar_img, (cam_img.shape[1], 400))
        return np.vstack([cam_img, lidar_img])

    def execute_command(self, cmd):
        if self.robot is None: return
        
        if cmd == 'reset_gyro' or cmd == 'reset':
            self.reset_gyro()
            return

        if cmd == 'forward': self.robot.move_forward(100)
        elif cmd == 'backward': self.robot.move_backward(100)
        elif cmd == 'left': self.robot.turn_left(100)
        elif cmd == 'right': self.robot.turn_right(100)
        elif cmd == 'stop': self.robot.stop()

    def destroy_node(self):
        if self.cap.isOpened(): self.cap.release()
        super().destroy_node()

async def main_loop(node):
    print(f"ðŸ”— ê´€ì œ ì„œë²„ ì ‘ì† ì‹œë„: {SERVER_URI}")
    async with websockets.connect(SERVER_URI) as ws:
        print(f"âœ… ì„œë²„ ì ‘ì† ì™„ë£Œ! (ID: {ROBOT_ID})")
        while True:
            fused = node.get_fused_image()
            _, buf = cv2.imencode('.jpg', fused, [cv2.IMWRITE_JPEG_QUALITY, 60])
            await ws.send(buf.tobytes())

            try:
                msg = await asyncio.wait_for(ws.recv(), timeout=0.001)
                node.execute_command(msg)
            except asyncio.TimeoutError: pass
            except Exception:
                print("âš ï¸ ì„œë²„ ì—°ê²° ëŠê¹€")
                break
            await asyncio.sleep(0.03)

def main():
    rclpy.init()
    node = IntegratedFleetNode()
    t = threading.Thread(target=rclpy.spin, args=(node,), daemon=True)
    t.start()
    try:
        asyncio.run(main_loop(node))
    except KeyboardInterrupt:
        print("ì¢…ë£Œ ì¤‘...")
    finally:
        if node.robot: 
            node.robot.stop()
            try: node.robot.cleanup()
            except: pass
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()